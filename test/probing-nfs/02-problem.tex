\subsection{The nonlinear filtering problem}
In this chapter we work with dynamical model given by a deterministic and chaotic ODE. Our model state is $d$-dimensional and the flow corresponding to the model is denoted by $\phi:\mathbb R \times \mathbb R^d\to\mathbb R^d$. We observe the model every $g$ units of time. So the model state $x_k$ follows a discrete-time deterministic dynamical system $f_g \stackrel{\rm def}{=} \phi(g, \cdot): \mathbb{R}^d \to \mathbb{R}^d$. The observations $y_k \in \mathbb{R}^q$ is related to the model state by the observation operator (a linear projection throughout this chapter) $H: \mathbb{R}^d \to \mathbb{R}^q$ for $k = 0, 1, \dots$, as follows:
\begin{align}
&x_{k+1} = f_g(x_k), \quad x_0 \sim \mu \,, \label{eq-state--probing-nfs}\\
&y_{k} = Hx_k + \eta_k \,, \quad  \label{eq-obs--probing-nfs}
\end{align}
where $\mu$ is the initial distribution of the model state $x_0$ at time 0,  and $\eta_k \sim \mathcal{N}(0_q, \sigma^2I_q)$ are \emph{iid} Gaussian errors in the observation, and are assumed independent of $\mu$. Given observations $y_0, y_1, \cdots, y_n$, the goal of filtering is to estimate the conditional distribution of the model state at time $n$ conditioned on observations up to that time: $x_n|y_{0:n} \sim \pi_{n}(\mu)$, where the dependence on the distribution $\mu$ of the initial condition $x_0$ is made explicit since our focus will be on filter stability. %

\subsection{Filter stability}\label{ssec-def-stab--probing-nfs} 
In practice we often do not know the initial distribution $\mu$. In such a case, when a different initial condition $\nu$ is chosen, one obtains a different filter, denoted by $\pi_{n}(\nu)$, by using the same set of observations and using the same algorithm. A measure of robustness of a filtering algorithm is how well it is able to "forget" the initial distribution, which motivates the following definitions.
{\color{mypink}

There are two different kinds of randomness that one needs to deal with in the setup above, the initial condition and the observation noise. Suppose $x_0:\Omega \to\mathbb R^d$ is our random initial condition. Consider $x_0(\omega)$, a realization of this initial condition. Now that we have fixed a realization of $x_0$, $\pi_n(\nu)$ and $\pi_n(\mu)$ become random measures whose randomness is determined only by the observation noise. For $x_0(\omega)$ we can compute the following expectation with respect to the observation noise 
\begin{align}
    \mathbb E \left|\int_{\mathbb R^d}  h(x)\, {{\pi_n(\mu, dx)}} - \int_{\mathbb R^d}  h(x)\, {{\pi_n(\nu, dx)}}\right|
\end{align}
for a bounded, continuous function $h$. If this expectation approaches $0$ as $n\to\infty$ for any such $h$ we can say that the filter is "pointwise" stable for the initial realization $x_0(\omega)$. And if the filter is "pointwise" stable for almost all realizations of $x_0$, we call the filter stable.  

\cite{reddy2021stability} explores the "true" filter stability for deterministic dynamics. Below we adapt the definition for numerical filter stability. Below $\hat\pi$ denotes the numerical approximation of the true filter $\pi$.
\begin{defn}[Stability-RA \cite{reddy2021stability}] A numerical filter is stable if  for any
measure $\nu$ with $\mu\ll\nu$ we have, 
\begin{align}
    \lim_{n\to\infty}\mathbb E \left|\int_{\mathbb R^d}  h(x)\, {{\hat\pi_n(\mu, dx)}} - \int_{\mathbb R^d}  h(x)\, {{\hat\pi_n(\nu, dx)}}\right|\label{def-stab-sumith--probing-nfs} = 0 \,,
\end{align}
for any bounded and continuous $h$, $\mu$-almost everywhere in the sense described above.
\label{def-stab-ra--probing-nfs} \end{defn}
Note that the expectation above is taken with respect to the observation noise only. Although \eqref{def-stab-sumith--probing-nfs} captures the notion of filter stability quite well, from a computational perspective we can improve on it in the following aspects. 
\begin{itemize}
 \item Computing the expectation for every possible bounded and continuous function is infeasible.
\item In real world applications we might not have access to $\mu$ and therefore an expectation independent of $\mu$ is preferable.

\end{itemize}
In order to overcome above difficulties and to assess filter stability numerically, we devise the following definition which can be proven to be a stronger version of definition~\ref{def-stab-ra--probing-nfs} in an appropriate sense (see theorem~\ref{thm:strength--probing-nfs} in appendix).
\begin{defn}[Stability-MRA \cite{mandal2021stability}]A numerical filter is said to be stable if for any two distributions {$\nu_1, \nu_2$}, the following holds, 
\begin{align}
    {\lim_{n\to\infty}\mathbb E[D(\hat\pi_n(\nu_1), \hat\pi_n(\nu_2))]} = 0 \,,
\label{eq-stablaw--probing-nfs} \end{align}
$\mu$-almost everywhere, where $D$ is a distance on $\mathcal P(\mathbb R^d)$, the space of probability measures on $\mathbb R^d$.
\label{def-stab--probing-nfs} \end{defn}

Note that even with the modifications, definition~\ref{def-stab--probing-nfs} remains hard to compute in the following aspects.
\begin{itemize}
    \item Computing the limit for every possible pair $\nu_1, \nu_2$ is infeasible.
    \item Computing the limit for every possible initial realization $x_0(\omega)$ is infeasible.
\end{itemize}

The last two difficulties also arise in definition~\ref{def-stab-ra--probing-nfs} and are unavoidable in some sense in a complete definition of filter stability. But even with these difficulties we can explore numerical filter stability in a meaningful albeit slightly limited way.  Although we demonstrate results for a single realization $x_0(\omega)$ here, this realization was generated randomly and different initial realizations yield qualitatively similar results which are consistent with the stability definition~\ref{def-stab--probing-nfs} and hence are not included in the paper to avoid repetition.
}

The main aim of this chapter is to study the stability of two popular filtering algorithms, namely the particle filter (PF) and the ensemble Kalman filter (EnKF) by studying the limit in~\eqref{eq-stablaw--probing-nfs}, where we choose the Wasserstein metric $W_2$ as our distance $D$ on $\mathcal P(\mathbb R^d)$. Previous work \cite{mandal2021stability} has shown these filters to be stable. Here we study the rate of convergence of the expectation in \eqref{eq-stablaw--probing-nfs} and how it varies with respect to the time between the observations denoted by $g$ and the observational uncertainty or the error variance $\sigma^2$. Thus we study $\mathbb{E}[D(\hat{\pi}_n(\nu_1), \hat{\pi}_n(\nu_2))]$ as a function of time $n$ for PF and EnKF algorithms. {\color{mypink}In the following discussion we sometimes abuse the notation and use $\pi$ to mean $\hat \pi^{\rm PF}$ or $\hat \pi^{\rm EnKF}$ with clear context.} We now describe these numerical filtering algorithms, followed in section~\ref{ssec-sink--probing-nfs} by a description of the Sinkhorn algorithm for computing distances between probability distributions.

\subsection{Ensemble Kalman Filters}\label{ssec-enkf--probing-nfs}
Kalman filters provide the closed form solutions to the Bayesian filtering equations in the scenario when the dynamic and measurement models are linear Gaussian or if the state equation~\eqref{eq-state--probing-nfs} looks like 
\begin{align}
   x_{k+1}=A_k x_k + \alpha_k \,, \label{eq-state-linear--probing-nfs} 
\end{align}
where $\alpha_k\sim\mathcal N(\mathbf{0},Q_k)$. The filtering distribution in this special case turns out to be Gaussian. The mean and covariance of this distribution is computed recursively in two steps, a prediction step where the effect of the hidden dynamics is captured and $p(x_k|y_{1:k-1})$ is computed and an update step where the observation $y_k$ is taken into account to give the filtering distribution $p(x_k|y_{1:k})$ using Baye's rule and well-known properties of the multivariate Gaussian distribution.

Ensemble Kalman filters can be thought of as an approximation of the original Kalman filter where the filtering distribution is represented by a collection of particles, as is the norm in Monte Carlo-based methods. The ensemble representation is akin to  dimension reduction which leads to computational feasibility for systems with large state space dimension $d$.\cite{Evensen03}. Localization, which is the process of weeding out long range spurious correlations, has made EnKF more applicable as well as wildly popular in high-dimensional data assimilation problems for spatially extended systems. For a discussion about localization see \cite{carrassi2018data}. We use Gaspari-Cohn function as our choice of localization function {\color{mypink}with radius set to 2}. 
\begin{algorithm}[!t]
\textcolor{mypink}{Initialize $N$ particles $\{x_0^i\}_{i=1}^N$ according to the initial distribution and set $x_0^{i,a}=x_0^i$ \\
Set $\rho$ as the Gaspari-Cohn localization matrix \cite{carrassi2018data}.\\
\For{$k=1,\cdots,n$}{
    \For{$i=1,\cdots,N$}{
        $x^{i,f}_{k}\leftarrow f_g(x_{k-1}^{i,a})$
    }
    $m_{k}^{f}\leftarrow \frac{1}{N}\sum_{i}x_{k}^{i,f}$\\ %
    $P_{k}^{f}\leftarrow \rho \circ \frac{\sum_{i}\left(x_{k}^{i,f}-m_{k}^{f}\right)\left(x_{k}^{i,f}-m_{k}^{f}\right)^\top}{N-1}$\\
    $K \leftarrow P^{f}_{k}H^{T} \left[HP^{f}_{k} H^{T}+R_{k}\right]^{-1}$\\
    \For{$i=1,\cdots,N$}{
        Sample $\eta^{i}_{k} \sim \mathcal{N}(0_q, \sigma^2I_q)$\\
        $y^{i}_{k}\leftarrow y_{k}+\eta^{i}_{k}$\\
        $x^{i,a}_{k} \leftarrow x^{i,f}_{k}+K\left[y^{i}_{k}-Hx^{i,f}_{k} \right]$
        }
    $\hat\pi_k \leftarrow\frac{1}{N}\sum_{i=1}^N \delta_{x^{i, a}_k}$
}
\caption{EnKF with covariance localization in state-space. $\circ$ denotes Hadamard product.}
\label{algo-enkf--probing-nfs} 
}
\end{algorithm}
{\color{mypink} The details of the exact implementation that we use can be found in algorithm~\ref{algo-enkf--probing-nfs}.}

\subsection{Particle Filters}\label{ssec-pf--probing-nfs}
Particle-filters are also Monte Carlo-based filters that recursively compute importance sampling approximations of the filtering distribution $p(x_k|y_{1:k})$. PFs also follow the Bayesian paradigm of two-step recursion with prediction and update steps. The filtering distribution is represented as a collection of weighted particles. In the prediction step the particles are evolved in time according to $\eqref{eq-state--probing-nfs}$ which gives us the prior for the next Bayesian update step where the weights are adjusted appropriately to account for the observation. For an excellent overview of the PF algorithm see \cite{doucet2009tutorial}. PFs do not rely on linearity or Gaussianity of dynamic of observation models which make them powerful but unless the number of particles scale exponentially with $d$, PFs experience weight degeneracy and provide poor estimates \cite{bengtsson1981dynamic}. In order to combat weight degeneracy, a resampling step is performed after the Bayesian update where particles with negligible weights are replaced with particles with higher weights. Many variants of the standard or the bootstrap PF have been proposed and the interested reader can see \cite{farchi2018comparison} for a discussion. However, applying PFs on problems with significantly high dimensions still remains a challenge. 

We use the bootstrap particle filter for our experiments with a stochastic resampling step where we place a Gaussian distribution with a pre-determined, small covariance {\color{mypink}$\tilde\sigma^2$ (set to be $0.5$ in the actual experiments)} around the best-performing particles and sample new particles according to the weights. 
{\color{mypink} The details of the exact algorithm can be found in algorithm~\ref{algo-bpf--probing-nfs}.}
\begin{algorithm}[!t]
\textcolor{mypink}{Initialize $N$ particles $\{x_0^i\}_{i=1}^N$ according to the initial distribution with equal weights $\left\{w_0^i=\frac{1}{N}\right\}_{i=1}^N$. Set $\tilde\sigma$. Below $S[i]$ denotes $i$-th element of $S$.\\
 \For{$k=0,\cdots,n$}{
      \If{$k>0$}{
      \For{$i=1,\cdots,N$}{
            $x^i_k\leftarrow f_g(S[i])$
            }
      }
      Sample $u\sim\mathcal{U}\left(0, \frac{1}{N}\right)$\\
      \For{$i=1,\cdots,N$}{
            $w^i_k\leftarrow p(y_k|x_k^i)$\\
            $U_{i} \leftarrow u + \frac{i-1}{N}$
            }
      $W\leftarrow\sum_{i=1}^Nw^i_k$\\
      \For{$i=1,\cdots,N$}{ 
            \If{$|\{U_j:\sum_{l=1}^{i-1}w^l_k \le WU_j\le\sum_{l=1}^{i}w^l_k\}|>0$}{
                    tag $x^i_k$ as significant
            }
            }
      Set $S\leftarrow\{x^{i_1}_k, x^{i_2}_k, \cdots, x^{i_m}_k\}$ as the set of  significant particles and compute $N_j\propto w^{i_j}_k:  \sum_{j=1}^mN_j = N$.\\
      \For{$j=1, \cdots, m$}{
            $S\leftarrow S\cup\{N_j-1\text{ samples from }\mathcal{N}(x^{i_j}_k, \tilde\sigma^2I_d)\}$
            }
    $\hat\pi_k \leftarrow\frac{1}{N}\sum_{i=1}^N\delta_{S[i]}$
  }
 \caption{BPF with offspring-based resampling}\label{algo-bpf--probing-nfs}}
\end{algorithm}

{\color{mypink}\subsection{Choice of distance \texorpdfstring{$D$}{Lg}} Although the stability definitions are independent of  any kind of specific distance and can be computed with other choices of $D$ we choose $D$ to be the $2$nd Wasserstein distance $W_2$. We justify our choice with the reasons below.
\begin{itemize}
    \item There is an efficient algorithm for approximating $W_p$ which is described below. 
    \item Some nice geometric properties of $W_p$ e.g. metrizing the convergence in law \cite{feydy2019interpolating} are missing from other distances or distance-substitutes like the  total variation distance and  the KL-divergence. 
    \item Moreover, $W_p$ does not require the notion of absolute continuity unlike KL-divergence or Hellinger distance which is useful for comparing empirical distributions.
\end{itemize}
For a comparison of these distances the interested reader may see \cite{arjovsky2017wasserstein} where example $1$ (learning parallel lines) depicts how the output of $W_p$ can often be intuitive because Wasserstein distances lift the standard metrics on $\mathbb R^d$ to the probability space $\mathcal P(\mathbb R^d)$ unlike KL-divergence or total variation. Lastly, we use $p=2$ for no reason other than the familiarity of the $2$-norm on Euclidean spaces.}

\subsection{Sinkhorn divergence} \label{ssec-sink--probing-nfs}

The $p$-th Wasserstein distance ($W_p$) between probability measures with $p$-th finite moment on metric spaces have many desirable geometric features which stems form the fact that its definition extends the distance function on the metric space to a distance on the space of probability measures on the metric space. For a discussion see \cite{feydy2019interpolating, arjovsky2017wasserstein}. $W_1$ or the earth mover's distance has been used in various problems e.g. comparing colour histograms, solving resource allocation problems etc. When applied to two sampling distributions with both having sample size $k$, computing $W_1$ is equivalent to solving a constrained linear programming problem in $n = k^2$ variables. Since LPPs take $O(n^3)$ time to solve a problem with $n$ variables, computing $W_1$ takes $O(k^6)$ time which is prohibitively expensive.

In recent years it has been noted that by regularizing the optimization problem that defines the Wasserstein distance, one can attempt to solve the dual to the regularized problem which is akin to solving a convex optimization problem. For a comprehensive discussion see \cite{genevay2019entropy}. The dual problem can be solved using a variant of the Sinkhorn-Knopp algorithm for finding a doubly-stochastic matrix given a square matrix with positive entries. The solution to the regularized problem is known as the Sinkhorn divergence since it fails to satisfy the triangle inequality and is not an exact distance on the space of probability measures.

{\color{mypink}Here we focus on the case $p=2$.} For two probability measures $\mu$ and $\nu$ on $\mathbb R^d$ with finite first and second moments, the Sinkhorn divergence $S_\varepsilon$ is defined as follows \cite{feydy2019interpolating}.
\begin{align}
    &\text{OT}_\varepsilon(\mu, \nu) \stackrel{\text{def}}{=} \min_{\pi \in \mathbb{S}}\left[\int\|x-y\|_2^2\,d\pi(x, y) + \varepsilon\text{KL}(\pi|\mu\otimes\nu)\right] \,, \label{def-ot--probing-nfs}\\
    &\text{S}_\varepsilon(\mu, \nu) \stackrel{\text{def}}{=} \text{OT}_\varepsilon(\mu, \nu) -\frac{1}{2}\text{OT}_\varepsilon(\mu, \mu)-\frac{1}{2}\text{OT}_\varepsilon(\nu, \nu) \,, \label{def-sink--probing-nfs}
\end{align}
where the minimisation is over the set $\mathbb{S}$ of distributions $\pi$ with the first and second marginals being $\mu$ and $\nu$ respectively  
and $\text{KL}$ is the Kullback–Leibler divergence.
Moreover, it turns out \cite{feydy2019interpolating} that
\begin{align}
    \lim_{\varepsilon \to0}\sqrt{S_\varepsilon(\mu, \nu)} = W_2(\mu, \nu) \,,\label{eq-sinkhorn-limit--probing-nfs}
\end{align}
and therefore for small enough $\varepsilon$ we 
obtain a good approximation of $W_2$. We use the following notation for this approximation: $D_\varepsilon = \sqrt{S_\varepsilon}$.

In our experiments we compute $S_\varepsilon(\mu, \nu)$ for sampling distributions $\mu=\sum_{i=1}^N\mu_i\delta_{x_i}$ and $\nu=\sum_{j=1}^M\nu_j\delta_{y_j}$ with $\varepsilon=0.01$ where $\{x_i\}_{i=1}^N$ and $\{y_j\}_{j=1}^M$ are points in $\mathbb R^d$. {\color{mypink} A detailed justification of this choice of $\varepsilon$ is in appendix~\ref{ssec-dw--probing-nfs}.} The Sinkhorn divergence algorithm being a fixed point iteration is extremely fast. The exact procedure is given in algorithm~\ref{algo-sink--probing-nfs}. The authors of \cite{feydy2019interpolating} show that the algorithm is parallelizable with respect to sample-size. The dimension dependence of the algorithm is only explicitly apparent while calculating the distance matrix and consequently the algorithm itself scales only linearly in $d$. But to accurately represent the underlying distribution with increasing dimension one would require to compute $S_\varepsilon$ with increasing sample size. For a detailed discussion of sample complexity of the Sinkhorn divergence see chapter 3 of \cite{genevay2019entropy}.
\begin{algorithm}[!t]
 \hspace*{\algorithmicindent} \textbf{Input: } $\{\mu_i\}_{i=1}^N, \{x_i\}_{i=1}^N, \{\nu_j\}_{j=1}^M, \{y_j\}_{j=1}^M$ \\
 \hspace*{\algorithmicindent} \textbf{Output: } $S_\varepsilon\left(\sum_{i=1}^N\mu_i\delta_{x_i},\sum_{j=1}^M\nu_j\delta_{y_j} \right)$\\ 
Note the definition, $\text{LSE}_{k=1}^LV_k\stackrel{\text{def}}{=}\log\sum_{k=1}^L\exp(V_k)$.\\
Initialize $a_i\leftarrow0\;\forall\; i=1,\cdots,N$ and $ b_j\leftarrow 0,\;\forall\; j=1,\cdots,M$.\\
iteration $\leftarrow 0$\\
\While{$\min$\{$L_1$ relative errors in $a$ and $b$\} $> 0.1\%$  }{
    \For{$i=1,\cdots, N$}{
        $a_i \leftarrow\
        -\varepsilon\text{LSE}_{k=1}^M\left(\log\nu_k+\frac{1}{\varepsilon}b_k - \frac{1}{\varepsilon}\|x_i-y_k\|_2^2 \right)$} %
    \For{$j=1,\cdots, M$}{
        $b_j \leftarrow\
        -\varepsilon\text{LSE}_{k=1}^N\left(\log\mu_k+\frac{1}{\varepsilon}a_k - \frac{1}{\varepsilon}\|x_k-y_j\|_2^2 \right)$}\
iteration $\leftarrow$   iteration + 1}\
$\text{OT}_{\mu, \nu}\leftarrow\sum_{i=1}^N\mu_i a_i +\sum_{j=1}^M \nu_j b_j$\\
Initialize $a_i\leftarrow0\;\forall\; i=1,\cdots,N$ and $ b_j\leftarrow 0,\;\forall\; j=1,\cdots,M$.\\
\While{$L_1$ relative error in $a > 0.1\%$}{
    \For{$i=1,\cdots, N$}{
        $a_i \leftarrow
        \frac{1}{2}\left[a_i - \varepsilon\text{LSE}_{k=1}^N\left(\log\mu_k+\frac{1}{\varepsilon}a_k - \frac{1}{\varepsilon}\|x_i-x_k\|_2^2 \right)\right]$}
    } %
\While{$L_1$ relative error in $b > 0.1\%$}{
    \For{$j=1,\cdots, M$}{
        $b_j \leftarrow\
        \frac{1}{2}\left[b_j - \varepsilon\text{LSE}_{k=1}^M\left(\log\nu_k+\frac{1}{\varepsilon}b_k - \frac{1}{\varepsilon}\|y_j-y_k\|_2^2 \right)\right]$}
    } %
$S_\varepsilon\leftarrow \text{OT}_{\mu, \nu} - \sum_{i=1}^N\mu_i a_i -\sum_{j=1}^M \nu_j b_j$
 \caption{Computation of $S_\varepsilon$}
\label{algo-sink--probing-nfs}
\end{algorithm}
