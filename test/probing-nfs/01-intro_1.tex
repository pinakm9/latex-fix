

The problem of predicting the state of a complex dynamical system is
ubiquitous in many scientific and engineering fields. In the context
of earth sciences, weather prediction and reanalysis of past climate
are major examples of such state estimation problems, which have two
main ingredients: (i) a dynamical model, usually deterministic, of the
system and (ii) partial, usually sparse, and needless to say, noisy,
observations. The process of combining these observations with the
model to get an ``optimal'' state estimate is commonly called data
assimilation - a term introduced in earth sciences~\cite{Carrassi-etal2008, fletcher2017data, Kalnay03}.

The mathematical formulation of this problem in a Bayesian framework
encapsulates the information from the model in terms of a prior
distribution, and the observational likelihood is used to obtain a
posterior distribution for the model state~\cite{ApteH07, law2015data}. For dynamical systems,
this is precisely the problem of nonlinear filtering, where the
posterior distribution itself changes with time and is conditioned on
observations up to that time. This posterior is called the {\it
filter} or the {\it filtering distribution}~\cite{sarkka2013bayesian, vanleeuwen2015book, asch2016data}.

A crucial characteristic of the atmospheric and oceanic dynamics is
their chaotic nature, manifested in sensitive to initial conditions. Thus a natural question is
whether the filter is also sensitive to the choice to the initial
distribution. In nonlinear filtering, this appears in the form of a
question about the stability of the filter~\cite{chigansky2009intrinsic, chigansky2006stability, crisan2011handbook}. A filter is stable if two
different initial distributions lead to the same filtering
distribution asymptotically in time. This is a desirable property for
a filter since the choice of the initial distribution is arbitrary and
we desire the filter to ``forget'' about this arbitrary choice. Thus
filter stability is an extensively studied topic, but mainly in the context of stochastic dynamics with only limited results for deterministic dynamical systems~{\color{mypink}\cite{reddy2021stability, oljavca2021exponential, reddy2019asymptotic, Cerou2000LongTB}}.

In practice, nonlinear filters need to be implemented numerically and we
will focus on two of the most commonly used methods, namely, particle
filters (PF) and ensemble Kalman filters (EnKF). The stability of
particle filters has been extensively studied~\cite{Chopin2020, whiteley2013stability} while very few theoretical results are known for the stability of EnKF~\cite{del2018stability}, though some results related to filter divergence (which is quite distinct from an unstable filter) and accuracy for the EnKF are available~\cite{KLS14, law2016filter, gottwald2013mechanism}. We
note that the assumptions used to prove stability of PF are
not satisfied by a deterministic dynamical model and thus their
stability in the context of data assimilation needs to be explored
numerically. This is the main aim of the present paper.

In order to assess filter stability directly using the definition
(see definition~\eqref{def-stab--probing-nfs}), we need to compute distances between
probability distributions. This has been a challenging task, but recently proposed Sinkhorn algorithm provides an efficient method for this task~\cite{genevay2019entropy, genevay2018learning, feydy2019interpolating, arjovsky2017wasserstein}. One of the novelties of this chapter is to demonstrate the use of the Sinkhorn algorithm in the context of data assimilation for directly studying stability.

Numerical studies of filter divergence, especially in the context of twin experiments where synthetic observations are generated using the model, have focused on assessing whether the filter remains bounded or whether the `error' or `bias' of the filter (commonly called RMSE, i.e. distance of the filter mean from the numerical trajectory which is used to generate the synthetic observations) remains bounded in time~\cite{KLS14, law2016filter}. But this does not provide a direct indication of stability as defined in~\eqref{def-stab--probing-nfs}. In this chapter, we demonstrate that there is a linear relationship between the filter error and the distance between two filters started with two different initial distributions, the latter giving a more appropriate measure of stability. This direct relation between filter stability and filter RMSE for particle and ensemble Kalman filters for deterministic dynamics is the other main contribution of this chapter.

The outline of the paper is as follows. The next section~\ref{sec-problem--probing-nfs} introduces the mathematical setting for the problem of filter stability. This is followed, in section~\ref{sec-method--probing-nfs}, by a description of the dynamical model we use (Lorenz-96), the filtering algorithms (particle filter and ensemble Kalman filter), and the Sinkhorn algorithm for computing distances between probability distributions. The following section~\ref{sec-results--probing-nfs} presents the numerical results, followed, in section~\ref{sec-conclude--probing-nfs}, by a discussion including avenues for further research.

