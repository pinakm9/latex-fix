In this work we present some practical implementations of popular constrained optimization algorithms in infinite dimensional Hilbert spaces. Both penalty and augmented Lagrangian methods produce decent, comparable solutions for our toy problems in terms of various metrics. Dimension of the Hilbert space $W$ is an important factor when it comes to the difference in the run times of penalty and augmented Lagrangian algorithms. When $W$ is infinite dimensional we might be able to achieve considerably lower run times for the augmented Lagrangian algorithm compared to the penalty method since updating the multiplier is generally less expensive than solving the subproblem in the penalty method. Some constraints like Gauss's law can be implemented reasonably well through architecture. Different update rules for the Lagrange multiplier lead to different variants of algorithm~\ref{algo:dl-al-infinite--var-ml} exploring which is a worthwhile topic for future research. The geometry of the objective function in the subproblems and the distribution of their optima also deserve further exploration.     