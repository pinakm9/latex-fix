Before discussing our algorithm for solving the problems stated in section~\ref{sec-prob--var-ml}, we briefly look at constrained optimization algorithms for finite dimensional problems and their infinite dimensional analogues since they illustrate the guiding principles that will help us devise our own algorithm. 


\subsection{Constrained optimization algorithms in finite dimensions}
Unconstrained optimization problems are typically easier to solve than constrained optimization problems and they are often solved using variants of gradient descent or Newton's method \cite{bonnans2006numerical}, \cite{jorge2006numerical}. Therefore, in order to solve constrained problems we often transform them into unconstrained problems first. When $X, W$ are finite dimensional, in order to solve problem~\eqref{eq:con-opt--var-ml} we can convert it from a constrained optimization problem to a sequence of unconstrained subproblems as follows,
\begin{align}
    u_k=\underset{u\in X}\arginf \mathcal L(u, \mu_k)\stackrel{\rm def}{=}f(u) + \frac{\mu_k}{2}|g(u)|_W^2,\;k=1,2,\cdots\label{eq:seq-uncon--var-ml}
\end{align}
where $|\cdot|_W$ and  denotes the canonical norm on $W$ and $\{\mu_k\}_{k=1}^\infty$ is a positive increasing sequence such that $\mu_k\uparrow\infty$ and $u_k$ is the exact global solution to the $k$-th subproblem. It can be shown that every limit point of $\{u_k\}_{k=1}^\infty$ is a solution to the original constrained problem, for a proof see theorem~17.1 in \cite{jorge2006numerical} or for a local version of the statement see theorem~1 in \cite{polyak1971convergence}. The strategy of using subproblems \eqref{eq:seq-uncon--var-ml} to solve \eqref{eq:con-opt--var-ml} is known as the quadratic \textit{penalty method}. In case we have access to only approximate solutions to the subproblems then limit points of these approximate solutions might be infeasible or they might only satisfy the first order KKT condition  \cite{kuhn2013nonlinear}, \cite{gordon2012karush}, \cite{boltyanski1998geometric} rather than being global minimizers. Moreover, the Hessian of the unconstrained objective function $\mathcal L$ becomes ill-conditioned as $\mu_k\uparrow\infty$. If we attempt to find an approximate solution to \eqref{eq:seq-uncon--var-ml} by trying to satisfy the first order condition using Newton's method, we quickly run into significant numerical errors when $\mu_k$ is large. For an excellent discussion of the nuances associated with the penalty method see chapter~17 in \cite{jorge2006numerical}. Typically the convergence rate of the quadratic penalty method is $O(k^{-\frac{1}{2}})$ but for strongly convex problems it increases to $O(k^{-1}) $  \cite{li2017convergence}, \cite{polyak1971convergence}.


In order to avoid ill-conditioning we can modify our subproblems as follows,
\begin{align}
    u_k=\underset{u\in X}\arginf\mathcal L_A(u, \mu_k, \lambda_k)\stackrel{\rm def}{=} f(u) + \frac{\mu_k}{2}|g(u)|_W^2 + \langle\lambda_k, g(u)\rangle_W,\;k=1,2,\cdots\label{eq:seq-uncon-al--var-ml}
\end{align}
where $\langle\cdot\rangle_W$ is the canonical inner product on $W$, $\{\mu_k\}_{k=1}^\infty$ is a positive, nondecreasing sequence but not necessarily unbounded and $\lambda_k$ follows the update rule,
\begin{align}
    \lambda_{k+1} = \lambda_k + \mu_k g(u_k)\label{eq:mul-update--var-ml}
\end{align}
This update rule is the consequence of an attempt to satisfy the first order condition for optimality. In this setting, $\mu_k$ and $\lambda_k$ play the roles of the penalty factor for deviating from the constraint and the Lagrange multiplier respectively. This method is known as the \textit{augmented Lagrangian method}. It can be shown that, under suitable conditions, if $\lambda_k$ converges to $\lambda^*$ then $\exists \,\mu^*>0$ such that for $\mu\ge\mu^*$, any local solution to the original constrained problem is a local minimizer of $\mathcal L_A(\cdot, \mu, \lambda^*)$, see theorem~17.5 in \cite{jorge2006numerical} or for a global version of this statement see theorem~5.2 in \cite{birgin2014practical}. This gives the augmented Lagrangian method a strong theoretical foundation but in practice we might only have approximate knowledge of $\lambda^*$. In such a case i.e. when $\lambda_k$ is close to $\lambda^*$, it can be shown that a local minimizer of $\mathcal L_A(\cdot, \mu, \lambda_k)$ solves the original constrained problem for large enough $\mu$, see theorem~17.6 in \cite{jorge2006numerical} or proposition~4.2.3 in \cite{bertsekas1995athena}. These results show that the augmented Lagrangian method can approximately solve \eqref{eq:con-opt--var-ml} when either the penalty $\mu$ is large or we have good knowledge of the optimal Lagrange multiplier $\lambda^*$. The appeal of the augmented Lagrangian method therefore lies in the possibility that we can replace the requirement that $\mu_k\uparrow\infty$ with the convergence of the Lagrange multiplier $\lambda_k$ thus avoiding the ill-conditioning of the Hessian and all the numerical difficulties that arise because of it. 


\subsection{Constrained optimization algorithms in infinite dimensions} When $X$ is infinite dimensional and $f(\cdot),\langle g(\cdot), g(\cdot)\rangle_W$ are lower-semicontinuous functionals, limit points of the exact global solutions to the subproblems are solutions to the original constrained problem, for a proof see theorem~1 in \cite{dussault2007penalty} and for a treatment of the penalty method on general topological spaces see \cite{fiacco1969generalized}. The augmented Lagrangian method has also been extended in many different scenarios where $X$ is an infinite dimensional Hilbert space by Ito and Kunisch \cite{ito1990augmented}, \cite{ito1990augmentedvar}, \cite{ito2008lagrange}. More recently the case when $X$ is an infinite dimensional Banach space has been considered by Kanzow et al \cite{kanzow2018augmented}. If we assume that problem~\eqref{eq:con-opt--var-ml} has a solution, $f, g$ are twice continuously Fr√©chet differentiable near the solution, derivative of $g$ at the solution is surjective, a Lagrange multiplier exists for this solution, $f$ is weakly lower-semicontinuous and $g$ maps weakly convergent sequences to weakly convergent sequences then we can prove that the augmented Lagrangian subproblems have local solutions, the Lagrange multiplier $\lambda_k$ converges to $\lambda^*$ and these local solutions converge to a local solution of \eqref{eq:con-opt--var-ml}. For an in-depth look at the technical details, we refer the reader to chapter~3 of \cite{ito2008lagrange}. 

\subsection{Deep learning variants for infinite dimensional algorithms}
The first challenge in implementing these algorithms is representing elements of $X$ and $W$ when they are infinite dimensional. A direct approach to do this would be to represent an element of $X$ as a neural network $u_{\eta}^\mathcal{A}$  and in case $W$ is infinite dimensional, we can represent the Lagrange multiplier as another network $\lambda_\xi^\mathcal{B}$ where $\eta, \xi$ represent the trainable parameters of the networks and $\mathcal A, \mathcal B$ represent the structure or architecture of the networks. Universal approximation theorems~\cite{pinkus1999approximation}, \cite{de2021approximation} imply that with appropriately chosen $\mathcal A, \mathcal B$ we might be able to sufficiently approximate the solutions to the subproblems. Suppose the dimensions of $\eta, \xi$ or the number of trainable parameters are $a, b$ respectively. Then the subproblems in the penalty algorithm can be rewritten as,
\begin{align}
    \eta_k=\underset{\eta\in \mathbb R^a}\arginf \mathcal L(u_{\eta}^{\mathcal A}, \mu_k)=f(u_{\eta}^{\mathcal A}) + \frac{\mu_k}{2}|g(u_{\eta}^{\mathcal A})|_W^2,\;k=1,2,\cdots\label{eq:seq-uncon-net--var-ml}
\end{align}
Similarly, the subproblems in the augmented Lagrangian algorithm can be rewritten as, 
\begin{align}
    \eta_k=\underset{\eta\in \mathbb R^a}\arginf \mathcal L_A(u_{\eta}^{\mathcal A}, \mu_k, \lambda_{\xi_k}^{\mathcal B})=f(u_{\eta}^{\mathcal A}) + \frac{\mu_k}{2}|g(u_{\eta}^{\mathcal A})|_W^2 + \langle\lambda_{\xi_k}^{\mathcal B}, g(u_{\eta}^{\mathcal A})\rangle_W,\;k=1,2,\cdots\label{eq:seq-uncon-al-net--var-ml}
    \end{align}
When $W$ is infinite dimensional, the Lagrange multiplier update rule can be rewritten as,
\begin{align}
\lambda_{\xi_{k+1}}^{\mathcal B} = \lambda_{\xi_k}^{\mathcal B} + \mu_k g(u_{\eta_k}^{\mathcal A})\label{eq:mul-update-net--var-ml}
\end{align}
 Note that, with this rewriting our infinite-dimensional subproblems have become finite dimensional since $a$ is finite. The update rule \eqref{eq:mul-update-net--var-ml} can not be implemented directly since the Lagrange multipliers are functions rather than finite dimensional vectors in this scenario. Therefore, we try to find the optimal $\xi_{k+1}$ that makes the left hand side of \eqref{eq:mul-update-net--var-ml} functionally or in an $L^2$ sense, equal to the right hand side by solving the following optimization problem, 
\begin{align}
    \xi_{k+1}=\underset{\xi\in\mathbb R^b}\arginf\left|\lambda_{\xi}^{\mathcal B}-\lambda_{\xi_{k}}^{\mathcal B}-\mu_k g(u_{\eta_k}^{\mathcal A})\right|_W^2\label{eq:xi-update--var-ml}
\end{align}
If we solve $K$ subproblems then we approximate our final solution as $u_{\eta_K}$. In order to solve each subproblem in \eqref{eq:seq-uncon-net--var-ml} and \eqref{eq:seq-uncon-al-net--var-ml} we use our solution to the last subproblem as an initial guess and perform gradient descent. In order to solve \eqref{eq:xi-update--var-ml} we use $\xi_k$ as an initial guess since we expect the sequence $\lambda_{\xi_k}^{\mathcal B}$ to converge. The selection of $\mu_k$ is an important part of the algorithm but no general purpose techniques for this selection are available in the literature. Larger $\mu_k$ results in better theoretical convergence rates while deteriorating the numerical estimates at same time, see section~3.3 in \cite{ito2008lagrange} for comments on this topic. The update rule in \eqref{eq:mul-update--var-ml} can be modified in different ways to achieve better estimates when one has some extra information about the problem \eqref{eq:con-opt--var-ml}, see the ALM algorithm in \cite{ito2008lagrange} for example. But in practice such information is nearly impossible to come by and therefore we will stick to the simple update rule in \eqref{eq:mul-update--var-ml}. The deep learning variants of the penalty method, augmented Lagrangian method when $W$ is finite dimensional and augmented Lagrangian method when $W$ is infinite dimensional can found in algorithms \ref{algo:dl-penalty--var-ml} (${\rm P}^\infty$), \ref{algo:dl-al-finite--var-ml} (${\rm AL}_{\rm F}^\infty$), \ref{algo:dl-al-infinite--var-ml} (${\rm AL}_\infty^\infty$) respectively. 

\begin{algorithm}[!ht]
\caption{${\rm P}^\infty$: Infinite dimensional penalty algorithm}
\label{algo:dl-penalty--var-ml}
\begin{algorithmic}[1]
    \STATE Choose architecture $\mathcal A$, penalty factor sequence $\{\mu_k\}_{k=1}^\infty$, adaptive learning rate $\{\delta_{k, j}\}_{k, j=1}^\infty$ and stopping criteria $\{P_k\}_{k=1}^\infty, \{Q_{k, j}\}_{k, j=1}^\infty$
    \STATE $k\leftarrow0$
    \WHILE{stopping criterion $P_k$ is not met}
        \STATE $k \leftarrow k+1$
        \IF{$k=1$}
                \STATE Initialize $\eta$ randomly
            \ELSE
                \STATE Initialize $\eta\leftarrow \eta_{k-1}$
        \ENDIF
        \STATE $j\leftarrow 1$
        \WHILE{stopping criterion $Q_{k, j}$ is not met}
            \STATE $L\leftarrow f(u_{\eta}^{\mathcal A})+\frac{\mu_k}{2}|g(u_{\eta}^{\mathcal A})|^2_W$
            \STATE $\eta\leftarrow\eta-\delta_{k, j}\nabla_\eta L$
            \STATE $j\leftarrow j+1$
        \ENDWHILE
        \STATE $\eta_k\leftarrow\eta$
    \ENDWHILE
    \STATE $u_{\eta_k}^{\mathcal A}$ is our approximate solution to \eqref{eq:con-opt--var-ml}
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[!ht]
\caption{${\rm AL}^\infty_{\rm F}$: Infinite dimensional augmented Lagrangian algorithm when $W$ is finite dimensional}
\label{algo:dl-al-finite--var-ml}
\begin{algorithmic}[1]
    \STATE Choose architectures $\mathcal A$, penalty factor sequence $\{\mu_k\}_{k=1}^\infty$, adaptive learning rate $\{\delta_{k, j}\}_{k, j=1}^\infty$ and stopping criteria $\{P_k\}_{k=1}^\infty, \{Q_{k, j}\}_{k, j=1}^\infty$
    \STATE $k\leftarrow0$
    \WHILE{stopping criterion $P_k$ is not met}
        \STATE $k \leftarrow k+1$
        \IF{$k=1$}
                \STATE Initialize $\eta$ randomly
        \ELSE
                \STATE Initialize $\eta\leftarrow \eta_{k-1}$
        \ENDIF
        \STATE $j\leftarrow 1$
        \WHILE{stopping criterion $Q_{k, j}$ is not met}
            \STATE $L\leftarrow f(u_{\eta}^{\mathcal A})+\frac{\mu_k}{2}|g(u_{\eta}^{\mathcal A})|^2_W + \langle\lambda_{\xi_k}^{\mathcal B}, g(u_{\eta}^{\mathcal A})\rangle_W$
            \STATE $\eta\leftarrow\eta-\delta_{k, j}^A\nabla_\eta L$
            \STATE $j\leftarrow j+1$
        \ENDWHILE
        \STATE $\eta_k\leftarrow\eta$
        \STATE $\xi_{k+1}\leftarrow\xi_k + g(u_{\eta_k}^{\mathcal A})$
    \ENDWHILE
    \STATE $u_{\eta_k}^{\mathcal A}$ is our approximate solution to \eqref{eq:con-opt--var-ml}
\end{algorithmic}
\end{algorithm}


\begin{algorithm}[!ht]
\caption{${\rm AL}_\infty^\infty$: Infinite dimensional augmented Lagrangian algorithm when $W$ is infinite dimensional}
\label{algo:dl-al-infinite--var-ml}
\begin{algorithmic}[1]
    \STATE Choose architectures $\mathcal A$, $\mathcal B$, penalty factor sequence $\{\mu_k\}_{k=1}^\infty$, adaptive learning rates $\{\delta_{k,j}^A\}_{k,j=1}^\infty$, $\{\delta_{k, j}^B\}_{k,j=1}^\infty$ and stopping criteria $\{P_k\}_{k=1}^\infty, \{Q_{k,j}^A\}_{k, j=1}^\infty, \{Q_{k,j}^B\}_{k, j=1}^\infty$
    \STATE $k\leftarrow0$
    \WHILE{stopping criterion $P_k$ is not met}
        \STATE $k \leftarrow k+1$
        \IF{$k=1$}
                \STATE Initialize $\eta$ randomly
                \STATE Initialize $\xi$ randomly
            \ELSE
                \STATE Initialize $\eta\leftarrow \eta_{k-1}$
        \ENDIF
        \STATE $j\leftarrow 1$
        \WHILE{stopping criterion $Q_{k, j}^A$ is not met}
            \STATE $L\leftarrow f(u_{\eta}^{\mathcal A})+\frac{\mu_k}{2}|g(u_{\eta}^{\mathcal A})|^2_W + \langle\lambda_{\xi_k}^{\mathcal B}, g(u_{\eta}^{\mathcal A})\rangle_W$
            \STATE $\eta\leftarrow\eta-\delta_{k,j}^A\nabla_\eta L$
            \STATE $j\leftarrow j+1$
        \ENDWHILE
        \STATE $\eta_k\leftarrow\eta$
        \STATE $j\leftarrow 1$
        \WHILE{stopping criterion $Q_{k, j}^B$ is not met}
            \STATE $L_\lambda\leftarrow \left|\lambda_{\xi}^{\mathcal B}-\lambda_{\xi_{k}}^{\mathcal B}-\mu_{k} g(u_{\eta_{k}}^{\mathcal A})\right|_W^2$
            \STATE $\xi\leftarrow\xi-\delta_{k,j}^B\nabla_\xi L_\lambda$
            \STATE $j\leftarrow j+1$
        \ENDWHILE
        \STATE $\xi_{k+1}\leftarrow\xi$
    \ENDWHILE
    \STATE $u_{\eta_k}^{\mathcal A}$ is our approximate solution to \eqref{eq:con-opt--var-ml}
\end{algorithmic}
\end{algorithm}


