Pierre de Fermat authored many important works on his method of maxima and minima, out of which the last two were titled \textit{The analysis of refractions} and \textit{The synthesis of refractions}. These contained derivations of the law of refraction now commonly known as \textit{Snell's law}. In these papers Fermat states his intuition about the nature of physical laws as, \textit{"nature operates by means and ways that are easiest and
fastest"} \cite{goldstine2012history}. Even though the ancient Greeks had considered some classic problems in calculus of variations such as  isoperimetric problems \cite{pappus1933pappus}, Fermat's proclamations are one of the first instances where we encounter the notion that the laws of physics can often be stated in terms of optimization problems. This notion takes its final form as the principle of stationary action in modern physics appearing in nearly every subfield from classical mechanics, thermodynamics, relativity, quantum mechanics, string theory and everything in between \cite{coopersmith2017lazy}, \cite{rojo2018principle}. Since Fermat's time calculus of variations in general has found applications in most fields dealing with mathematical models, be it chemistry \cite{quapp2008chemical} or economics \cite{guzowska2015calculus} and its stochastic counterpart is useful in economics \cite{oksendal1997introduction} and mathematical finance \cite{malliavin2006stochastic}. 

Calculus of variations deals with finding functions as optimizer of functionals under constraints. Due to recent technical advancements in automatic differentiation and machine learning, it has become a popular paradigm to cast many engineering or basic science problems such as finding language models for Shakespearean text \cite{jhamtani2017shakespearizing}, learning generative models for natural images \cite{huang2018introduction}, solving partial differential equations \cite{blechschmidt2021three} etc as optimization problems and then solve them using well-established optimization algorithms like stochastic gradient descent \cite{ruder2016overview}, \cite{bottou2007tradeoffs}. This pattern very naturally yields itself to the \textit{function-finding} problems of calculus of variations. In finite dimensions, constrained optimization problems are routinely handled with \textit{penalty method}, \textit{augmented Lagrangian method} and their many variants \cite{jorge2006numerical}, \cite{bonnans2006numerical}, \cite{bertsekas1995athena}. In infinite dimensions or for function finding problems analogues of these algorithms have been discussed extensively in terms of theory \cite{ito2008lagrange}, \cite{kanzow2018augmented}, \cite{dussault2007penalty}, \cite{fiacco1969generalized}. But numerical implementation of these algorithms remain few and far between. This work aims to bridge the gap between the theory of infinite dimensional constrained optimization algorithms and their practical implementations using deep learning. Recently variational problems with essential boundary conditions have been explored by Huang et al \cite{huang2021augmented}. In this work we explore more general problems. Our goal is to evaluate our algorithms, rather than solving the specific problems we list here. We, therefore, apply them on some simple toy problems with known solutions. Our problems are either taken from the classics in calculus of variations or inspired by physics. 



