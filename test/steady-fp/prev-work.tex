An extensive amount of work has been done on the topic of numerically solving Fokker-Planck equations. A large numer of these works are based on traditional PDE solving techniques such as finite difference~\cite{berezin1987conservative, whitney1970finite, sepehrian2015numerical} and finite element~\cite{naprstek2014finite, masud2005application} methods. For a comparison of these traditional methods we refer the reader to the comparative study~\cite{pichler2013numerical} by Pitcher et al.~where the methods have been applied to 2 and 3 dimensional examples. 


In recent times efforts have been made to devise methods that are applicable in dimensions higher than 3. Tensor decomposition methods~\cite{Hackbusch2005HierarchicalKT, kolda2009tensor} are an important toolkit while dealing with high-dimensional problems and they are proving to be useful in designing numerical solvers for PDEs~\cite{ballani2013projection, kressner2010krylov}.  For stationary Fokker-Planck equations, Sun and Kumar~\cite{sun2014numerical} proposed a tensor decomposition and Chebyshev spectral differentiation based method. In this method drift functions are approximated with a sum of functions that are separable in spatial variables, an well-established paradigm for solving PDEs. The differential operator for the stationary FPE is then discretized and finally a least squares problem is solved to find the final solution. The normalization is enforced via addition of a penalty term in the optimization problem. The high-dimensional integral for the normalization constraint in this method is replaced with  products of one dimensional integrals and therefore becomes computable.   

Chen and Majda~\cite{chen2018efficient} proposed a hybrid method that utilizes both kernel and sample based density approximation to solve FPEs that originate from a specific type of SDE referred to as a conditional Gaussian model.
% \begin{equation}
% \begin{aligned}
%     d\mathbf{u_I} = [A_0(t, \mathbf{u_I}) + A_1(t, \mathbf{u_I})\mathbf{u_{II}}]\,dt + \Sigma_I(t, \mathbf{u_I})\,dW_I(t)\\
%     d\mathbf{u_{II}} = [a_0(t, \mathbf{u_I}) + a_1(t, \mathbf{u_I})\mathbf{u_{II}}]\,dt + \Sigma_{II}(t, \mathbf{u_I})\,dW_{II}(t)\label{eq:conditional-Gaussian-SDE--steady-fp}
% \end{aligned}
% \end{equation}
The special structure of the SDE allows one to approximate %$p(\mathbf{u_{II}}(t))$ 
the marginal of a subset of variables as a Gaussian mixture with parameters that satisfy auxiliary SDEs while the marginal of the remaining variables 
% $p(\mathbf{u_I}(t))$ 
is approximated with a non-parametric kernel based method. Finally the joint distribution 
% $p(\mathbf{u_I}(t), \mathbf{u_{II}}(t))$
is computed with a hybrid expression. Using this method Chen and Majda computed the solution to a 6 dimensional conceptual model for turbulence. Note that, among our examples only L63 falls under this special  structure.

In recent years machine learning has also been applied to solve SFPEs. Xu et al~\cite{xu2020solving} solved two and three dimensional stationary FPEs with deep learning. Their method enforced normalization via a penalty term in the loss function that represented a Monte-Carlo estimate of the solution. Although simple and effective in lower dimensions, this normalization strategy loses effectiveness in higher dimensions. Zhai et al~\cite{zhai2022deep} have proposed a combination of deep learning and Monte-Carlo method to solve stationary FPEs. The normalization constraint here is replaced with a regularizing term in the loss function which tries to make sure the final solution is close to a pre-computed Monte-Carlo solution. This strategy is more effective than having to approximate high-dimensional integrals and the authors successfully apply their method on Chen and Majda's 6 dimensional example.






